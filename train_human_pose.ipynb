{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Human pose estimation\n",
    "\n",
    "Inspect and visualize data loading and pre-processing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import utils\n",
    "import visualize\n",
    "from visualize import display_images\n",
    "import model as modellib\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"mylogs\")\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco_humanpose.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "Run one of the code blocks below to import and load the configurations to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS COCO Dataset\n",
    "import coco\n",
    "config = coco.CocoConfig()\n",
    "COCO_DIR = \"D:/Eigene Dateien/Dokumente/coco\"  # TODO: enter your own path here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=8.91s)\n",
      "creating index...\n",
      "index created!\n",
      "Skeleton: (19, 2)\n",
      "Keypoint names: (17,)\n",
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n",
      "Skeleton: (19, 2)\n",
      "Keypoint names: (17,)\n",
      "Train Keypoints Image Count: 64115\n",
      "Train Keypoints Class Count: 2\n",
      "  0. BG                                                \n",
      "  1. person                                            \n",
      "Val Keypoints Image Count: 2693\n",
      "Val Keypoints Class Count: 2\n",
      "  0. BG                                                \n",
      "  1. person                                            \n"
     ]
    }
   ],
   "source": [
    "# MS COCO Dataset\n",
    "import coco\n",
    "config = coco.CocoConfig()\n",
    "COCO_DIR = \"D:/Eigene Dateien/Dokumente/coco\"  # TODO: enter value here\n",
    "# Load dataset\n",
    "assert config.NAME == \"coco\"\n",
    "# Training dataset\n",
    "# load person keypoints dataset\n",
    "train_dataset_keypoints = coco.CocoDataset(task_type=\"person_keypoints\")\n",
    "train_dataset_keypoints.load_coco(COCO_DIR, \"train\")\n",
    "train_dataset_keypoints.prepare()\n",
    "\n",
    "#Validation dataset\n",
    "val_dataset_keypoints = coco.CocoDataset(task_type=\"person_keypoints\")\n",
    "val_dataset_keypoints.load_coco(COCO_DIR, \"val\")\n",
    "val_dataset_keypoints.prepare()\n",
    "\n",
    "print(\"Train Keypoints Image Count: {}\".format(len(train_dataset_keypoints.image_ids)))\n",
    "print(\"Train Keypoints Class Count: {}\".format(train_dataset_keypoints.num_classes))\n",
    "for i, info in enumerate(train_dataset_keypoints.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    "print(\"Val Keypoints Image Count: {}\".format(len(val_dataset_keypoints.image_ids)))\n",
    "print(\"Val Keypoints Class Count: {}\".format(val_dataset_keypoints.num_classes))\n",
    "for i, info in enumerate(val_dataset_keypoints.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ceate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_image:0\", shape=(None, 1024, 1024, 3), dtype=float32)\n",
      "WARNING:tensorflow:From D:\\Users\\LStue\\anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "[<tf.Tensor 'fpn_p2/BiasAdd:0' shape=(None, 256, 256, 256) dtype=float32>, <tf.Tensor 'fpn_p3/BiasAdd:0' shape=(None, 128, 128, 256) dtype=float32>, <tf.Tensor 'fpn_p4/BiasAdd:0' shape=(None, 64, 64, 256) dtype=float32>, <tf.Tensor 'fpn_p5/BiasAdd:0' shape=(None, 32, 32, 256) dtype=float32>, <tf.Tensor 'fpn_p6/MaxPool:0' shape=(None, 16, 16, 256) dtype=float32>]\n",
      "rpn_class:  Tensor(\"rpn_class/concat:0\", shape=(None, None, 2), dtype=float32)\n",
      "rpn_bbox:  Tensor(\"rpn_bbox/concat:0\", shape=(None, None, 4), dtype=float32)\n",
      "x im fpn_classifier_graph:  (2, None, 7, 7, 256)\n",
      "s im fpn_classifier_grapf:  (None, None, 8)\n",
      "Loading weights from  C:\\Users\\LStue\\Mask_RCNN_Humanpose\\mask_rcnn_coco_humanpose.h5\n"
     ]
    }
   ],
   "source": [
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"training\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True,exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "print(\"Loading weights from \", COCO_MODEL_PATH)\n",
    "# model.keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train heads\n",
      "\n",
      "Starting at epoch 0. LR=0.002\n",
      "\n",
      "Checkpoint Path: C:\\Users\\LStue\\Mask_RCNN_Humanpose\\mylogs\\coco20201216T1211\\mask_rcnn_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_keypoint_mask_conv1   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn1   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv2   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn2   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv3   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn3   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv4   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn4   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv5   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn5   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv6   (TimeDistributed)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn6   (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv7   (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn7   (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv8   (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn8   (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_keypoint_mask_deconv   (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'ListWrapper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-72fd097b4f4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             layers='heads')\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Training - Stage 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Finetune layers from ResNet stage 4 and up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Mask_RCNN_Humanpose\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers)\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Checkpoint Path: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3069\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trainable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3070\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLEARNING_MOMENTUM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3072\u001b[0m         \u001b[1;31m# Work-around for Windows: Keras fails on Windows when using\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Mask_RCNN_Humanpose\\model.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, learning_rate, momentum)\u001b[0m\n\u001b[0;32m   2922\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2923\u001b[0m             self.keras_model.add_loss(\n\u001b[1;32m-> 2924\u001b[1;33m                 tf.reduce_mean(layer.output, keepdims=True))\n\u001b[0m\u001b[0;32m   2925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m         \u001b[1;31m# Add L2 Regularization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\LStue\\anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_loss\u001b[1;34m(self, losses, inputs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_graph_network'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m           \u001b[1;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\LStue\\anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[1;34m(self, symbolic_loss)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[0mnew_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_loss_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[0mnew_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_loss_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insert_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_graph_network_add_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\LStue\\anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_insert_layers\u001b[1;34m(self, layers, relevant_nodes)\u001b[0m\n\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m     \u001b[1;31m# Insert layers and update other layer attrs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m     \u001b[0mlayer_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1440\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\LStue\\anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\data_structures.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;31m# List wrappers need to compare like regular lists, and so like regular\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     \u001b[1;31m# lists they don't belong in hash tables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unhashable type: 'ListWrapper'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'ListWrapper'"
     ]
    }
   ],
   "source": [
    "# Training - Stage 1\n",
    "print(\"Train heads\")\n",
    "model.train(train_dataset_keypoints, val_dataset_keypoints,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=15,\n",
    "            layers='heads')\n",
    "# Training - Stage 2\n",
    "# Finetune layers from ResNet stage 4 and up\n",
    "print(\"Training Resnet layer 4+\")\n",
    "model.train(train_dataset_keypoints, val_dataset_keypoints,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=20,\n",
    "            layers='4+')\n",
    "# Training - Stage 3\n",
    "# Finetune layers from ResNet stage 3 and up\n",
    "print(\"Training Resnet layer 3+\")\n",
    "model.train(train_dataset_keypoints, val_dataset_keypoints,\n",
    "            learning_rate=config.LEARNING_RATE / 100,\n",
    "            epochs=100,\n",
    "            layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
